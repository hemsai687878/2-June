{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6fb95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, welcome to nlp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case folding \n",
    "text =\"hello, Welcome to NLP\"\n",
    "\n",
    "# text =text.casefold() \n",
    "# text\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f391c0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello Welcome to NLP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "text =\"hello, #Welcome @to NLP\"\n",
    "re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4dd900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello Welcome123 to NLP'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re \n",
    "text =\"hello, #Welcome123 @to NLP\"\n",
    "re.sub(r\"[^a-zA-Z0-9\\s]\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e04009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello Welcome to NLP'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "text =\"hello, #Welcome123 @to NLP\"\n",
    "re.sub(r\"[^a-zA-Z\\s]\",\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28228252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "download(\"en_core_web_sm\")  # Downloads the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1d4c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Welcome to NLP\n"
     ]
    }
   ],
   "source": [
    "nlp =spacy.load('en_core_web_sm')\n",
    "text =\"hello, #Welcome123 @to NLP\"\n",
    "def clean_text(text):\n",
    "    cleaned_text=\"\".join(char for char in text if char.isalpha() or char.isspace())\n",
    "    doc =nlp(cleaned_text)\n",
    "    return \" \".join(token.text for token in doc)\n",
    "ckean_str =clean_text(text=text)\n",
    "print(ckean_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95aafd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', '#', 'Welcome123', '@', 'to', 'NLP']\n",
      "hello Welcome123 to NLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\heman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "text = \"hello, #Welcome123 @to NLP\"\n",
    "# nltk.download('punkt')\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "clean_token = [token for token in tokens if token.isalnum()]\n",
    "clean_str = \" \".join(clean_token)\n",
    "print(clean_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf82c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', '#', 'welcome123', '@', 'to', 'NLP']\n",
      "hello welcome123 to NLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\heman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\heman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "text =\"hello, #welcome123 @to NLP\"\n",
    "#nltk.download('sub-punkt')\n",
    "tokens =nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "clean_token=[token for token in tokens if token.isalnum()]\n",
    "clean_str =\" \".join(clean_token)\n",
    "print(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194641ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
